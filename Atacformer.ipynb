{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project: Visualizing and decoding chromatin dynamics with Atacformer\n"
      ],
      "metadata": {
        "id": "0lBHArKceSFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "We have developed a model called Atacformer, a transformer-based neural network trained on a large corpus of single-cell ATAC-seq (scATAC-seq) data. Atacformer learns biologically meaningful representations (embeddings) of individual cells based on their chromatin accessibility profiles.\n",
        "\n",
        "When new scATAC-seq data is passed through Atacformer, it produces low-dimensional embeddings of each cell. These embeddings can be used for visualization, clustering, classification, and interpretability analyses â€” offering a deep, data-driven view into regulatory identity.\n",
        "\n",
        "This project applies Atacformer to a rich time-course dataset to visualize cellular trajectories, predict developmental time, and interpret which genomic regions drive embedding formation using attention maps.\n",
        "\n",
        "## Goal\n",
        "\n",
        "The goal of this project is to apply Atacformer to the [GSE242421](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE242421) dataset to:\n",
        "\n",
        "1. Project and visualize cell embeddings over time  \n",
        "2. Train a model to predict each cellâ€™s timepoint from its Atacformer embedding  \n",
        "3. Extract and explore attention scores to interpret which genomic regions are most important at each stage  \n",
        "\n",
        "## Project Steps\n",
        "\n",
        "### Preparation\n",
        "\n",
        "1. Read the paper (PMC10592962) to understand the biological context and timeline of reprogramming  \n",
        "2. Explore the Geniml library (https://docs.bedbase.org/geniml/) for manipulating scATAC fragment files  \n",
        "3. Familiarize yourself with Atacformer input format, expected preprocessing steps, and model interface  \n",
        "\n",
        "### Step 1: Project Timepoint-Specific Embeddings\n",
        "\n",
        "1. Download and prepare data:  \n",
        "   - Get the 9 scATAC-seq fragment files (1 per timepoint) from GSE242421  \n",
        "   - Organize by timepoint (day 0 through day 8)  \n",
        "\n",
        "2. Preprocess:\n",
        "   - Might be necessary to use SnapATAC2 for QC on the fragments\n",
        "   - Use Geniml to gtokenize fragment files  \n",
        "   - Format data as needed for Atacformer input  \n",
        "\n",
        "3. Project through Atacformer:  \n",
        "   - Embed each cell using the pretrained model, for each time point\n",
        "\n",
        "4. Visualize:  \n",
        "   - Fit a UMAP on all embeddings together  \n",
        "   - For each timepoint:  \n",
        "     - Plot all original Atacformer model cells in light gray  \n",
        "     - Overlay current timepoint in color  \n",
        "     - Save as a time-lapse frame to visualize trajectory over time  \n",
        "\n",
        "### Step 2: Integrated Analysis â€” Predicting Reprogramming Time\n",
        "\n",
        "In addition to visualizing individual timepoints, perform an integrated analysis using all cells at once.\n",
        "\n",
        "1. Create dataset:  \n",
        "   - Combine all cellsâ€™ embeddings into one matrix  \n",
        "   - Assign each cell its corresponding timepoint as a label (e.g., integer from 0â€“8)  \n",
        "\n",
        "2. Train a classifier:  \n",
        "   - Use 80% of the data to train a model that predicts timepoint from the embedding (options: logistic regression, random forest, MLP)  \n",
        "   - Hold out 20% for testing  \n",
        "\n",
        "3. Evaluate performance:  \n",
        "   - Report accuracy, confusion matrix, and regression error (e.g., RMSE if using a regressor)  \n",
        "\n",
        "4. Feature and region importance:  \n",
        "   - Identify which embedding features or original genomic regions are most predictive of time  \n",
        "   - Use SHAP, feature importances, or attention-based explanations if possible  \n",
        "\n",
        "### Step 3: Explore Attention Scores â€” Interpreting the Embedding\n",
        "\n",
        "We're now going inside the black box to explore which genomic regions the model is using to form each cellâ€™s embedding.\n",
        "\n",
        "#### What are attention scores?\n",
        "\n",
        "- In a transformer, each token corresponds to a genomic region (e.g., binned genome or peak)  \n",
        "- Attention scores tell us which regions the model focused on when embedding a cell  \n",
        "\n",
        "#### What to do\n",
        "\n",
        "1. Extract per-cell attention scores:  \n",
        "   - From the modelâ€™s forward pass, extract attention matrices per layer and head  \n",
        "   - For each cell, identify which input tokens (regions) had the highest cumulative attention  \n",
        "\n",
        "2. Aggregate to pseudobulks:  \n",
        "   - Group cells by timepoint (or cluster)  \n",
        "   - Average attention scores across cells to get a pseudobulk attention profile  \n",
        "   - This gives you a ranked list of regions per timepoint, based on how much attention they received  \n",
        "\n",
        "3. Compare and correlate:  \n",
        "   - Compare attention-ranked regions across timepoints  \n",
        "   - Correlate high-attention regions with:  \n",
        "     - Known enhancers or promoters  \n",
        "     - Transcription factor binding motifs (e.g., ASCL1, NEUROD1)  \n",
        "     - External ChIP-seq/ATAC-seq annotations  \n",
        "     - Regions known to be active during reprogramming (from the original paper)  \n",
        "\n",
        "4. Optional visualization:  \n",
        "   - Generate genome-browserâ€“style attention tracks per timepoint  \n",
        "   - Highlight which loci (e.g., Pou3f4, Myt1l) are gaining or losing attention over time  \n",
        "\n",
        "## Additional Notes\n",
        "\n",
        "- If attention scores are difficult to access directly, contact Nathan LeRoy, author of Atacformer.\n",
        "- Consider simplifying attention score aggregation (e.g., averaging over heads/layers) for interpretability\n",
        "- In case it doesn't do well on fibroblast data (because maybe fibroblasts weren't well represented in the original data), it might make sense to do an unsupervised fine-tuning step prior to this, to help the foundation model out.\n",
        "- For the attention scores, this may be difficult or impossible due to the use of FlashAttention. Will need to explore to figure out what we can do.\n"
      ],
      "metadata": {
        "id": "e060seZseR6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's begin!"
      ],
      "metadata": {
        "id": "dmXV_LfveRo5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download all the files  \n",
        "Data is organized by days: D0-> D14"
      ],
      "metadata": {
        "id": "xvSFkPFdfAUZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnL0LijzNIhg"
      },
      "outputs": [],
      "source": [
        "!wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM7763nnn/GSM7763395/suppl/GSM7763395_D0.frag.bed.gz\n",
        "!wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM7763nnn/GSM7763396/suppl/GSM7763396_D2.frag.bed.gz\n",
        "# !wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM7763nnn/GSM7763397/suppl/GSM7763397_D4.frag.bed.gz\n",
        "# !wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM7763nnn/GSM7763398/suppl/GSM7763398_D6.frag.bed.gz\n",
        "# !wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM7763nnn/GSM7763399/suppl/GSM7763399_D8.frag.bed.gz\n",
        "# !wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM7763nnn/GSM7763400/suppl/GSM7763400_D10.frag.bed.gz\n",
        "# !wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM7763nnn/GSM7763401/suppl/GSM7763401_D12.frag.bed.gz\n",
        "# !wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM7763nnn/GSM7763402/suppl/GSM7763402_D14.frag.bed.gz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quality Control on dataset"
      ],
      "metadata": {
        "id": "ERQsIP84femU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfdjRfVZBLL2"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade snapatac2\n",
        "!pip install kaleido"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "During import fragments, it computes only basic QC metrics like the number of unique fragments per cell, fraction of duplicated reads and fraction of mitochondrial read"
      ],
      "metadata": {
        "id": "5IupnNuDgTIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget ftp://ftp.ncbi.nlm.nih.gov/geo/samples/GSM7763nnn/GSM7763395/suppl/GSM7763395_D0.frag.bed.gz"
      ],
      "metadata": {
        "id": "DShtlBsXmcUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbZw_lBaBBar"
      },
      "outputs": [],
      "source": [
        "import snapatac2 as snap\n",
        "\n",
        "fragment_files = [\n",
        "    \"GSM7763395_D0.frag.bed.gz\",\n",
        "    \"GSM7763396_D2.frag.bed.gz\"\n",
        "    # \"GSM7763397_D4.frag.bed.gz\",\n",
        "    # \"GSM7763398_D6.frag.bed.gz\",\n",
        "    # \"GSM7763399_D8.frag.bed.gz\",\n",
        "    # \"GSM7763400_D10.frag.bed.gz\",\n",
        "    # \"GSM7763401_D12.frag.bed.gz\",\n",
        "    # \"GSM7763402_D14.frag.bed.gz\"\n",
        "]\n",
        "\n",
        "data_objects = [\n",
        "    snap.pp.import_fragments(file, chrom_sizes=snap.genome.hg38, sorted_by_barcode=False)\n",
        "    for file in fragment_files\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write to h5ad file\n",
        "out_filenames = []\n",
        "for fragment_file, data in zip(fragment_files, data_objects):\n",
        "    base_name = fragment_file.replace(\".frag.bed.gz\", \"\")\n",
        "    out_filename = base_name + \".h5ad\"\n",
        "    out_filenames.append(out_filename)\n",
        "    data.write(out_filename)\n",
        "    print(f\"Saved {out_filename}\")"
      ],
      "metadata": {
        "id": "oplRyVFpVKys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute TSS enrichment scores and plot them to identify high quality reusable cells"
      ],
      "metadata": {
        "id": "GddLtRVSgbHc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLFFaKmON-Yj"
      },
      "outputs": [],
      "source": [
        "tsse_objects = [\n",
        "    snap.metrics.tsse(data, snap.genome.hg38) for data in data_objects\n",
        "]\n",
        "\n",
        "for tsse in tsse_objects:\n",
        "    snap.pl.tsse(tsse, interactive=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFjPsCJMRGgV"
      },
      "outputs": [],
      "source": [
        "for data in data_objects:\n",
        "  snap.pp.filter_cells(data, min_counts=5000, min_tsse=10, max_counts=100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization of data"
      ],
      "metadata": {
        "id": "wKvnaA7GfuJo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ibk55dG4kbYH"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade snapatac2 --use-deprecated=legacy-resolver\n",
        "!pip install kaleido --use-deprecated=legacy-resolver\n",
        "!pip install geniml[ml] --use-deprecated=legacy-resolver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install git+https://github.com/databio/geniml.git"
      ],
      "metadata": {
        "id": "IvD7tE7OcfLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"from geniml import __version__; print(__version__)\"\n"
      ],
      "metadata": {
        "id": "KWx8tzY5wBgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy"
      ],
      "metadata": {
        "id": "mliPdqjg0ras"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade huggingface_hub"
      ],
      "metadata": {
        "id": "s6jPsBL512rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from geniml.atacformer import AtacformerForCellClustering\n",
        "\n",
        "atac_model = AtacformerForCellClustering.from_pretrained(\"databio/atacformer-base-hg38\")\n",
        "atac_model = atac_model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "Rs_6ziBfjNzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU3O_HC_gXxW"
      },
      "outputs": [],
      "source": [
        "# Embed to Atacformer\n",
        "import scanpy as sc\n",
        "\n",
        "from gtars.tokenizers import Tokenizer\n",
        "# from geniml.tokenization import AnnDataTokenizer\n",
        "import geniml.tokenization\n",
        "print(dir(geniml.tokenization))\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer.from_pretrained(\"databio/atacformer-base-hg38\")\n",
        "data_objects = []\n",
        "cell_embeddings = []\n",
        "\n",
        "\n",
        "for out_filename in out_filenames:\n",
        "  data = sc.read_h5ad(out_filename)\n",
        "  data_objects.append(data)\n",
        "  tokens = tokenize_anndata(data, tokenizer)\n",
        "  input_ids = [t[\"input_ids\"] for t in tokens]\n",
        "  cell_embedding = atac_model.encode_tokenized_cells(\n",
        "    input_ids=input_ids,\n",
        "    batch_size=32,  # adjust based on your memory capacity\n",
        "  )\n",
        "  cell_embeddings.append(cell_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "07296817"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from umap import UMAP\n",
        "\n",
        "for i,data in enumerate(data_objects):\n",
        "  data.obsm[\"X_atacformer\"] = cell_embeddings[i].cpu().numpy()\n",
        "\n",
        "all_embeddings = np.vstack([data.obsm['X_atacformer'] for data in data_objects])\n",
        "timepoint_days = list(range(0, 16, 2))\n",
        "\n",
        "dataset_labels = []\n",
        "for i, data in enumerate(data_objects):\n",
        "    dataset_labels.extend([f\"dataset_{i}\"] * data.n_obs)\n",
        "dataset_labels = np.array(dataset_labels)\n",
        "\n",
        "umap_model = UMAP(n_neighbors=15, random_state=42)\n",
        "combined_umap = umap_model.fit_transform(all_embeddings)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(\n",
        "    x=combined_umap[:,0],\n",
        "    y=combined_umap[:,1],\n",
        "    hue=dataset_labels,\n",
        "    palette='tab10',\n",
        "    s=10\n",
        ")\n",
        "plt.title(\"UMAP of all datasets combined\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Integrated Analysis â€” Predicting Reprogramming Time"
      ],
      "metadata": {
        "id": "RpQUk5M0FAPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    all_embeddings, timepoint_days,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "7QkPIaxK7Y3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'LR': LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "        multi_class='ovr'\n",
        "    ),\n",
        "    'RF': RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'MLP': MLPClassifier(\n",
        "        hidden_layer_sizes=(128, 64),\n",
        "        max_iter=500,\n",
        "        random_state=42,\n",
        "        early_stopping=True,\n",
        "        validation_fraction=0.1\n",
        "    )\n",
        "}\n",
        "\n",
        "# scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train and evaluate each model\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    if 'MLP' in name:\n",
        "        X_tr, X_te = X_train_scaled, X_test_scaled\n",
        "    else:\n",
        "        X_tr, X_te = X_train, X_test\n",
        "\n",
        "    # Train\n",
        "    model.fit(X_tr, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred_train = model.predict(X_tr)\n",
        "    y_pred_test = model.predict(X_te)\n",
        "\n",
        "    # Get prediction probabilities (useful for analysis)\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_prob_test = model.predict_proba(X_te)\n",
        "    else:\n",
        "        y_prob_test = None\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_acc = accuracy_score(y_train, y_pred_train)\n",
        "    test_acc = accuracy_score(y_test, y_pred_test)\n",
        "    if 'LR' in name:\n",
        "      train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "      test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "      train_mae = mean_absolute_error(y_train, y_pred_train)\n",
        "      test_mae = mean_absolute_error(y_test, y_pred_test)\n",
        "      test_r2 = r2_score(y_test, y_pred_test)\n",
        "\n",
        "      # Store results\n",
        "      results[name] = {\n",
        "        'model': model, 'test_accuracy': test_acc, 'test_rmse': test_rmse,\n",
        "        'test_mae': test_mae, 'test_r2': test_r2, 'y_pred_test': y_pred_test\n",
        "      }\n",
        "\n",
        "      print(f\"Accuracy: {test_acc:.3f} | RMSE: {test_rmse:.2f} | MAE: {test_mae:.2f} | RÂ²: {test_r2:.3f}\")\n",
        "    else:\n",
        "      results[name] = {\n",
        "          'model': model, 'test_accuracy': test_acc, 'y_pred_test': y_pred_test\n",
        "        }\n",
        "\n",
        "      print(f\"Accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "XcjCIGJ4E83X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare all models in one plot\n",
        "fig, axes = plt.subplots(1, len(results), figsize=(5*len(results), 4))\n",
        "if len(results) == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "unique_timepoints = sorted(np.unique(y_test))\n",
        "labels = [f'Day {int(tp)}' for tp in unique_timepoints]\n",
        "\n",
        "for idx, (name, result) in enumerate(results.items()):\n",
        "    cm = confusion_matrix(y_test, result['y_pred_test'])\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=labels, yticklabels=labels, ax=axes[idx])\n",
        "\n",
        "    axes[idx].set_title(f'{name}\\nAcc: {result[\"test_accuracy\"]:.3f}')\n",
        "    axes[idx].set_xlabel('Predicted')\n",
        "    if idx == 0:\n",
        "        axes[idx].set_ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RTQcDoSdHjjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.geeksforgeeks.org/machine-learning/shap-a-comprehensive-guide-to-shapley-additive-explanations/"
      ],
      "metadata": {
        "id": "P-AFHsa8Jyau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost shap pandas scikit-learn matplotlib ipywidgets"
      ],
      "metadata": {
        "id": "OCkhyRlFDQrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "for model in models:\n",
        "  explainer = shap.Explainer(model)\n",
        "  shap_values = explainer(X_test)\n",
        "  shap.initjs()\n",
        "\n",
        "  shap.summary_plot(shap_values, X_test)"
      ],
      "metadata": {
        "id": "onsJii-HDVCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Explore Attention Scores â€” Interpreting the Embedding"
      ],
      "metadata": {
        "id": "xv496fuoE4MM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using atac_model\n",
        "# 4. Run forward pass to get attention\n",
        "atac_model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(\n",
        "        input_ids=torch.tensor(input_ids).to(\"cuda\"),\n",
        "        output_attentions=True\n",
        "    )\n",
        "\n",
        "    # outputs.attentions is a tuple: (num_layers, batch_size, num_heads, seq_len, seq_len)\n",
        "    attentions = outputs.attentions\n",
        "\n",
        "# Example: Get cumulative attention for first cell\n",
        "cell_idx = 0\n",
        "cell_attention = torch.stack(attentions)[:, cell_idx]  # (num_layers, num_heads, seq_len, seq_len)\n",
        "\n",
        "# Average across heads and layers\n",
        "avg_attention = cell_attention.mean(dim=0).mean(dim=0)  # (seq_len, seq_len)\n",
        "\n",
        "# Cumulative importance per token\n",
        "token_importance = avg_attention.sum(dim=0)  # Sum over source positions\n",
        "\n",
        "# Get top 10 most attended genomic regions\n",
        "top_tokens = torch.topk(token_importance, 10)\n",
        "print(\"Top token indices:\", top_tokens.indices.cpu().numpy())\n",
        "print(\"Top attention scores:\", top_tokens.values.cpu().numpy())"
      ],
      "metadata": {
        "id": "d9kC8f0pE5Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b618d0fd"
      },
      "source": [
        "print(f\"ðŸ” Analyzing attention for {len(input_ids_list)} cells...\")\n",
        "\n",
        "    # Extract attention scores using your existing setup\n",
        "    all_attention = []\n",
        "    atac_model.eval()\n",
        "\n",
        "    for i in tqdm(range(0, len(input_ids_list), batch_size)):\n",
        "        batch = input_ids_list[i:i+batch_size]\n",
        "\n",
        "        # Pad batch to same length\n",
        "        max_len = max(len(ids) for ids in batch)\n",
        "        padded = [ids + [0]*(max_len-len(ids)) for ids in batch]\n",
        "        masks = [[1]*len(ids) + [0]*(max_len-len(ids)) for ids in batch]\n",
        "\n",
        "        # Extract attention (using your approach!)\n",
        "        with torch.no_grad():\n",
        "            outputs = atac_model(\n",
        "                input_ids=torch.tensor(padded).to(\"cuda\"),\n",
        "                attention_mask=torch.tensor(masks).to(\"cuda\"),\n",
        "                output_attentions=True\n",
        "            )\n",
        "\n",
        "        # Process each cell in batch\n",
        "        for j, original_ids in enumerate(batch):\n",
        "            # Average across layers/heads, sum for token importance\n",
        "            cell_attn = torch.stack(outputs.attentions)[:, j].mean(dim=[0,1]).sum(dim=0)\n",
        "            all_attention.append(cell_attn[:len(original_ids)].cpu().numpy())\n",
        "\n",
        "    print(\"ðŸ“Š Creating pseudobulk profiles...\")\n",
        "\n",
        "    # Group cells and average attention\n",
        "    groups = defaultdict(list)\n",
        "    for i, group in enumerate(cell_groups[:len(all_attention)]):\n",
        "        groups[group].append(all_attention[i])\n",
        "\n",
        "    # Create profiles for each group\n",
        "    profiles = {}\n",
        "    for group_name, group_attentions in groups.items():\n",
        "        print(f\"  Processing {group_name}: {len(group_attentions)} cells\")\n",
        "\n",
        "        # Stack, pad, and average\n",
        "        max_regions = max(len(scores) for scores in group_attentions)\n",
        "        matrix = np.zeros((len(group_attentions), max_regions))\n",
        "        counts = np.zeros(max_regions)\n",
        "\n",
        "        for i, scores in enumerate(group_attentions):\n",
        "            matrix[i, :len(scores)] = scores\n",
        "            counts[:len(scores)] += 1\n",
        "\n",
        "        # Average where we have data\n",
        "        avg_scores = np.divide(matrix.sum(axis=0), counts,\n",
        "                              out=np.zeros(max_regions), where=counts>0)\n",
        "\n",
        "        # Get top regions\n",
        "        top_idx = np.argsort(avg_scores)[::-1][:top_k]\n",
        "\n",
        "        profiles[group_name] = pd.DataFrame({\n",
        "            'region_index': top_idx,\n",
        "            'attention_score': avg_scores[top_idx],\n",
        "            'rank': range(1, len(top_idx)+1),\n",
        "            'n_cells': len(group_attentions)\n",
        "        })"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}